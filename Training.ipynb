{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\myenv_RL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from DQN import DQN_Agent\n",
    "from QR_DQN import QR_DQN_Agent\n",
    "from IQN import IQN_Agent\n",
    "from NAF import NAF_Agent\n",
    "from TD3 import TD3_Agent\n",
    "from PPO import PPO_Agent\n",
    "from SAC import SAC_Agent\n",
    "\n",
    "import optuna\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import PatientPruner, MedianPruner\n",
    "\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF THE TRIAL OBJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below there are defined all the optimizer object for each agent. Choose the one you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_eps_start = trial.suggest_float(\"eps_start\", 0.95, 0.99)\n",
    "      int_eps_decay = trial.suggest_categorical(\"eps_decay\", [500, 750, 1000, 1250])\n",
    "      int_eps_end = trial.suggest_float(\"eps_end\", 0.025, 0.1)\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "\n",
    "      # init the agent\n",
    "      model = DQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            EPS_START=int_eps_start,\n",
    "            EPS_DECAY=int(int_eps_decay),\n",
    "            EPS_END=int_eps_end,\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=True)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD3_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_sd_noise = trial.suggest_float(\"sd_noise\", 0.3, 1)\n",
    "      int_sd_noise_decay = trial.suggest_float(\"sd_noise_decay\", 0.1, 0.99)\n",
    "      int_steps_decay_sd = trial.suggest_categorical(\"steps_decay_sd\", [5, 10, 15, 20])\n",
    "      int_cp_value = trial.suggest_float(\"cp_value\", 0.01, 0.2)\n",
    "      int_steps_update_policy = trial.suggest_categorical(\"steps_update_policy\", [2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_repetition = trial.suggest_categorical(\"repetition\", [2, 4, 6, 8 ,10])\n",
    "\n",
    "      # init the agent\n",
    "      model = TD3_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            SD_NOISE=int_sd_noise,\n",
    "            SD_DECAY=int(int_sd_noise_decay),\n",
    "            STEPS_DECAY_SD=int_steps_decay_sd,\n",
    "            CP_VALUE=int_cp_value,\n",
    "            STEP_UPT_POLICY=int(int_steps_update_policy),\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            REPETITION=int(int_repetition),\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAF_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_eps = trial.suggest_float(\"eps\", 0.5, 1)\n",
    "      int_eps_decay = trial.suggest_float(\"eps_decay\", 0.025, 0.1)\n",
    "      int_steps_decay = trial.suggest_categorical(\"steps_decay\", [5, 10, 15, 20, 40, 60])\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_repetition = trial.suggest_categorical(\"repetition\", [2, 4, 6, 8, 10])\n",
    "\n",
    "      # init the agent\n",
    "      model = NAF_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            EPSILON = int_eps,\n",
    "            EPSILON_DECAY=int_eps_decay,\n",
    "            STEPS_DECAY=int_steps_decay,\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            REPETITION=int(int_repetition),\n",
    "            N_EPISODES=200,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_DQN_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_eps_start = trial.suggest_float(\"eps_start\", 0.95, 0.99)\n",
    "      int_eps_decay = trial.suggest_categorical(\"eps_decay\", [500, 750, 1000, 1250])\n",
    "      int_eps_end = trial.suggest_float(\"eps_end\", 0.025, 0.1)\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_n_quantiles = trial.suggest_int(\"n_quantiles\", 40, 70)\n",
    "\n",
    "      # init the agent\n",
    "      model = QR_DQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            EPS_START=int_eps_start,\n",
    "            EPS_DECAY=int(int_eps_decay),\n",
    "            EPS_END=int_eps_end,\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            N_QUANTILES=int_n_quantiles,\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAC_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_entropy_param = trial.suggest_float(\"entropy\", 0.05, 0.2)\n",
    "      int_epochs = trial.suggest_int(\"epochs\", 4, 30)\n",
    "      int_steps_update = trial.suggest_categorical(\"steps_update\", [10, 20, 30])\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_repetition = trial.suggest_categorical(\"repetition\", [2, 4, 6, 8 ,10])\n",
    "\n",
    "      # init the agent\n",
    "      model = SAC_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            ENTROPY_PARAM=int_entropy_param,\n",
    "            K_EPOCHS=int_epochs,\n",
    "            STEPS_UPDATE=int_steps_update,\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            REPETITION=int(int_repetition),\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQN_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_eps_start = trial.suggest_float(\"eps_start\", 0.95, 0.99)\n",
    "      int_eps_decay = trial.suggest_categorical(\"eps_decay\", [500, 750, 1000, 1250])\n",
    "      int_eps_end = trial.suggest_float(\"eps_end\", 0.025, 0.1)\n",
    "      int_tau = trial.suggest_float(\"tau\", 0.0025, 0.0075)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_sub_agents = trial.suggest_int(\"sub_agents\", 2, 10)\n",
    "\n",
    "      # init the agent\n",
    "      model = IQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            GAMMA=int_gamma,\n",
    "            EPS_START=int_eps_start,\n",
    "            EPS_DECAY=int(int_eps_decay),\n",
    "            EPS_END=int_eps_end,\n",
    "            TAU=int_tau,\n",
    "            LR=int_lr,\n",
    "            SUB_AGENTS=int_sub_agents,\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPO_optim(trial):\n",
    "      # Define the space of hyperparameters to run the search for optimization\n",
    "      int_batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512])\n",
    "      int_num_batch_max = trial.suggest_int(\"max_n_batch\", 2, 10)\n",
    "      int_gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "      int_trunc_param = trial.suggest_int(\"trunc_param\", 2, 6)\n",
    "      int_lambda = trial.suggest_float(\"lambda\", 0.01, 0.99)\n",
    "      int_max_len_traj = int.suggest_int(\"len_max_traj\", 500, 2000)\n",
    "      int_n_actors = trial.suggest_int(\"n_actors\", 2, 6)\n",
    "      int_epochs = trial.suggest_int(\"epochs\", 4, 30)\n",
    "      int_clip_value = trial.suggest_float(\"clip_value\", 0.01, 0.3)\n",
    "      int_entropy = trial.suggest_float(\"entropy_coef\", 0.1, 0.6)\n",
    "      int_lr = trial.suggest_float(\"lr\", 1e-5, 1e-3)\n",
    "      int_repetition = trial.suggest_categorical(\"repetition\", [2, 4, 6, 8 ,10])\n",
    "\n",
    "      # init the agent\n",
    "      model = PPO_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "            BATCH_SIZE=int(int_batch_size),\n",
    "            NUM_BATCH_MAX=int_num_batch_max,\n",
    "            GAMMA=int_gamma,\n",
    "            TRUNC_PARAM=int_trunc_param,\n",
    "            LAMBDA=int_lambda,\n",
    "            MAX_LEN_TRAJ=int_max_len_traj,\n",
    "            N_ACTORS=int_n_actors,\n",
    "            K_EPOCHS=int_epochs,\n",
    "            CLIP_VALUE=int_clip_value,\n",
    "            COEF_H=int_entropy,\n",
    "            LR=int_lr,\n",
    "            REPETITION=int(int_repetition),\n",
    "            N_EPISODES=400,\n",
    "            PRINT_PLOT=False)\n",
    "      # run the training\n",
    "      model.training()\n",
    "      # return the loss to choose the hyper parameters\n",
    "      return  float(model.return_metric(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZATION OF THE HYPERPARAMETER OPTIMIZER AND RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, replace DQN_optim with the model you selected above (so replace it with the correct optim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = create_study(direction=\"maximize\", sampler=TPESampler(), pruner=PatientPruner(MedianPruner(), patience=3))\n",
    "study.optimize(QR_DQN_optim, n_trials=60, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET HYPERPARAMETERS AND RE-TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'gamma': 0.9870468671594415,\n",
       " 'eps_start': 0.9689218973923628,\n",
       " 'eps_decay': 1000,\n",
       " 'eps_end': 0.0841014572098897,\n",
       " 'tau': 0.003998980031293827,\n",
       " 'lr': 0.00037088923945978876}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\myenv_RL\\Lib\\site-packages\\gymnasium\\wrappers\\record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\matte\\Documents\\REI LEA\\Progetto Esame\\Deep-RL-Algo\\videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "                  BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                  GAMMA=best_param[\"gamma\"],\n",
    "                  EPS_START=best_param[\"eps_start\"],\n",
    "                  EPS_DECAY=best_param[\"eps_decay\"],\n",
    "                  EPS_END=best_param[\"eps_end\"],\n",
    "                  TAU=best_param[\"tau\"],\n",
    "                  LR=best_param[\"lr\"],\n",
    "                  N_EPISODES=600,\n",
    "                  PRINT_PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TD3_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "                  BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                  GAMMA=best_param[\"gamma\"],\n",
    "                  SD_NOISE=best_param[\"sd_noise\"],\n",
    "                  SD_DECAY=best_param[\"sd_noise_decay\"],\n",
    "                  STEPS_DECAY_SD=best_param[\"steps_decay_sd\"],\n",
    "                  CP_VALUE=best_param[\"cp_value\"],\n",
    "                  STEP_UPT_POLICY=best_param[\"steps_update_policy\"],\n",
    "                  TAU=best_param[\"tau\"],\n",
    "                  LR=best_param[\"lr\"],\n",
    "                  REPETITION=best_param[\"repetition\"],\n",
    "                  N_EPISODES=600,\n",
    "                  PRINT_PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NAF_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "                  BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                  GAMMA=best_param[\"gamma\"],\n",
    "                  EPSILON = best_param[\"eps\"],\n",
    "                  EPSILON_DECAY=best_param[\"eps_decay\"],\n",
    "                  STEPS_DECAY=best_param[\"steps_decay\"],\n",
    "                  TAU=best_param[\"tau\"],\n",
    "                  LR=best_param[\"lr\"],\n",
    "                  REPETITION=best_param[\"repetition\"],\n",
    "                  N_EPISODES=600,\n",
    "                  PRINT_PLOT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QR_DQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "                     BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                     GAMMA=best_param[\"gamma\"],\n",
    "                     EPS_START=best_param[\"eps_start\"],\n",
    "                     EPS_DECAY=best_param[\"eps_decay\"],\n",
    "                     EPS_END=best_param[\"eps_end\"],\n",
    "                     TAU=best_param[\"tau\"],\n",
    "                     LR=best_param[\"lr\"],\n",
    "                     N_QUANTILES=best_param[\"n_quantiles\"],\n",
    "                     N_EPISODES=600,\n",
    "                     PRINT_PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC_Agent(ENV_NAME=\"CarRacing-v3\",\n",
    "                  BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                  GAMMA=best_param[\"gamma\"],\n",
    "                  ENTROPY_PARAM=best_param[\"entropy\"],\n",
    "                  K_EPOCHS=best_param[\"epochs\"],\n",
    "                  STEPS_UPDATE=best_param[\"steps_update\"],\n",
    "                  TAU=best_param[\"tau\"],\n",
    "                  LR=best_param[\"lr\"],\n",
    "                  REPETITION=best_param[\"repetition\"],\n",
    "                  N_EPISODES=600,\n",
    "                  PRINT_PLOT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IQN_Agent(ENV_NAME=\"LunarLander-v2\",\n",
    "                     BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                     GAMMA=best_param[\"gamma\"],\n",
    "                     EPS_START=best_param[\"eps_start\"],\n",
    "                     EPS_DECAY=best_param[\"eps_decay\"],\n",
    "                     EPS_END=best_param[\"eps_end\"],\n",
    "                     TAU=best_param[\"tau\"],\n",
    "                     LR=best_param[\"lr\"],\n",
    "                     SUB_AGENTS=best_param[\"sub_agents\"],\n",
    "                     N_EPISODES=600,\n",
    "                     PRINT_PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO_Agent(ENV_NAME=\"CarRacing-v3\",            \n",
    "                 BATCH_SIZE=best_param[\"batch_size\"],\n",
    "                 NUM_BATCH_MAX=best_param[\"max_n_batch\"],\n",
    "                 GAMMA=best_param[\"gamma\"],\n",
    "                 TRUNC_PARAM=best_param[\"trunc_param\"],\n",
    "                 LAMBDA=best_param[\"lambda\"],\n",
    "                 MAX_LEN_TRAJ=best_param[\"len_max_traj\"],\n",
    "                 N_ACTORS=best_param[\"n_actors\"],\n",
    "                 K_EPOCHS=best_param[\"epochs\"],\n",
    "                 CLIP_VALUE=best_param[\"clip_value\"],\n",
    "                 COEF_H=best_param[\"entropy_coef\"],\n",
    "                 LR=best_param[\"lr\"],\n",
    "                 REPETITION=best_param[\"repetition\"],\n",
    "                 N_EPISODES=600,\n",
    "                 PRINT_PLOT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE BEST COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH1 = \"DQN_best_hyperparameters.json\"\n",
    "FILE_PATH2 = \"DQN_best_parameters.pt\"\n",
    "\n",
    "with open(FILE_PATH1, 'w') as json_file:\n",
    "    json.dump(best_param, json_file, indent=4)\n",
    "\n",
    "torch.save(model.return_weights(), FILE_PATH2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
